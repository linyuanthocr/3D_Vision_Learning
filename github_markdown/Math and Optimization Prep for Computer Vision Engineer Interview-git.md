
This markdown document includes 20 whiteboard-style problems and answers, covering key topics for the role of Computer Vision Engineer with a focus on ****pose estimation****, ****calibration****, and ****multi-sensor fusion****, including ****nonlinear optimization**** concepts relevant to CV technology.

---

## ğŸ”§ Pose Estimation


### 1. Reprojection Cost Function

****Problem:**** Given 3D world points and their 2D projections, write the cost function for pose estimation. Â 

****Answer:**** Â 


<div class="math">

\min_{R, t} \sum_{i=1}^N \left\| u_i - \pi(K(RX_i + t)) \right\|^2

</div>

![Pasted image 20250404095619.png](3D_Vision_Interview_questions/Pasted%20image%2020250404095619.png)

![Pasted image 20250404095640.png](3D_Vision_Interview_questions/Pasted%20image%2020250404095640.png)
![Pasted image 20250404095654.png](3D_Vision_Interview_questions/Pasted%20image%2020250404095654.png)

![Pasted image 20250404095729.png](3D_Vision_Interview_questions/Pasted%20image%2020250404095729.png)

![Pasted image 20250404095754.png](3D_Vision_Interview_questions/Pasted%20image%2020250404095754.png)

å…³äº å…¬å¼7.44ï¼šfirst-order Taylor expansion
![Pasted image 20250404133440.png](3D_Vision_Interview_questions/Pasted%20image%2020250404133440.png)


---


### 2. Distortion-Aware Projection

****Problem:**** How to handle significant distortion in pose estimation? Â 

****Answer:**** Use distortion-aware model (e.g., radial-tangential) and optimize using LM.
![Pasted image 20250404152529.png](3D_Vision_Interview_questions/Pasted%20image%2020250404152529.png)
  ![Pasted image 20250404152449.png](3D_Vision_Interview_questions/Pasted%20image%2020250404152449.png)
  
![Pasted image 20250404152510.png](3D_Vision_Interview_questions/Pasted%20image%2020250404152510.png)
![Pasted image 20250404153051.png](3D_Vision_Interview_questions/Pasted%20image%2020250404153051.png)

##### Undisort the image first. 

å½“ä½ çŸ¥é“ç›¸æœºå‚æ•°ï¼Œå¹¶ä¸”åªè€ƒè™‘å¾„å‘ç•¸å˜å’Œåˆ‡å‘ï¼ˆæ–œå‘ï¼‰ç•¸å˜æ—¶ï¼Œå›¾åƒå»ç•¸å˜é€šå¸¸é‡‡ç”¨çš„æ˜¯ **å°†æ–°ï¼ˆæœªç•¸å˜ï¼‰å›¾åƒä¸­çš„æ¯ä¸ªåƒç´ æ˜ å°„å›åŸå§‹ï¼ˆç•¸å˜ï¼‰å›¾åƒä¸­å¯»æ‰¾å¯¹åº”ä½ç½®ï¼Œç„¶åè¿›è¡Œåƒç´ æ’å€¼** çš„æ–¹æ³•ã€‚

è®©æˆ‘è¯¦ç»†è§£é‡Šä¸€ä¸‹è¿™ä¸ªè¿‡ç¨‹ï¼Œå¹¶è¯´æ˜ä¸ºä»€ä¹ˆé€šå¸¸ä¸é‡‡ç”¨â€œæ¯ä¸ªç•¸å˜ç‚¹æ˜ å°„åˆ°æ–°ç‚¹â€çš„æ–¹æ³•ï¼š

**ä¸ºä»€ä¹ˆä¸ç›´æ¥å°†æ¯ä¸ªç•¸å˜ç‚¹æ˜ å°„åˆ°æ–°ç‚¹ï¼Ÿ**

- **ç›®æ ‡å›¾åƒåƒç´ çš„å®Œæ•´æ€§:** ä½ çš„ç›®æ ‡æ˜¯ç”Ÿæˆä¸€ä¸ª**æ–°çš„ã€æœªç•¸å˜çš„å›¾åƒ**ã€‚è¿™ä¸ªæ–°å›¾åƒçš„åƒç´ ç½‘æ ¼æ˜¯è§„åˆ™çš„ã€‚å¦‚æœåªå°†åŸå§‹ç•¸å˜å›¾åƒä¸­çš„æ¯ä¸ªåƒç´ æ˜ å°„åˆ°ä¸€ä¸ªæ–°çš„ä½ç½®ï¼Œå¯èƒ½ä¼šåœ¨æ–°å›¾åƒä¸­ç•™ä¸‹â€œç©ºæ´â€æˆ–è€…åƒç´ åˆ†å¸ƒä¸å‡åŒ€çš„æƒ…å†µã€‚å› ä¸ºåŸå§‹ç•¸å˜åƒç´ çš„åˆ†å¸ƒæ˜¯ä¸è§„åˆ™çš„ï¼Œæ˜ å°„åå¾ˆéš¾ä¿è¯æ–°å›¾åƒçš„æ¯ä¸ªåƒç´ éƒ½æœ‰ä¸€ä¸ªå¯¹åº”çš„åŸå§‹åƒç´ ã€‚
- **æ’å€¼çš„å¿…è¦æ€§:** å³ä½¿æ¯ä¸ªåŸå§‹åƒç´ éƒ½èƒ½æ˜ å°„åˆ°ä¸€ä¸ªæ–°çš„ä½ç½®ï¼Œæ–°ä½ç½®çš„åæ ‡å¾ˆå¯èƒ½ä¸æ˜¯æ•´æ•°åƒç´ åæ ‡ã€‚ä¸ºäº†åœ¨æ–°å›¾åƒçš„æ•´æ•°åƒç´ ä½ç½®ä¸Šèµ‹äºˆåˆç†çš„é¢œè‰²å€¼ï¼Œä»ç„¶éœ€è¦è¿›è¡Œæ’å€¼ã€‚

**æ ‡å‡†çš„å»ç•¸å˜æµç¨‹ï¼š**

1. **åˆ›å»ºæ–°çš„ã€æœªç•¸å˜çš„å›¾åƒ:** é¦–å…ˆï¼Œä½ éœ€è¦åˆ›å»ºä¸€ä¸ªä¸åŸå§‹ç•¸å˜å›¾åƒå°ºå¯¸ç›¸åŒï¼ˆæˆ–è€…æ ¹æ®éœ€æ±‚è¿›è¡Œè°ƒæ•´ï¼‰çš„æ–°å›¾åƒï¼Œç”¨äºå­˜å‚¨å»ç•¸å˜åçš„ç»“æœã€‚è¿™ä¸ªæ–°å›¾åƒçš„åƒç´ åæ ‡æ˜¯è§„åˆ™çš„æ•´æ•°ç½‘æ ¼ã€‚
    
2. **éå†æ–°å›¾åƒçš„æ¯ä¸ªåƒç´ :** éå†è¿™ä¸ªæ–°å›¾åƒä¸­çš„æ¯ä¸€ä¸ªåƒç´ ç‚¹ (uundistortedâ€‹,vundistortedâ€‹)ã€‚
    
3. **åå‘æŠ•å½±åˆ°å½’ä¸€åŒ–å›¾åƒå¹³é¢:** å¯¹äºæ–°å›¾åƒä¸­çš„æ¯ä¸ªåƒç´ ç‚¹ï¼Œä½ éœ€è¦ä½¿ç”¨ç›¸æœºå†…å‚ï¼ˆä¾‹å¦‚ç„¦è· fxâ€‹,fyâ€‹ å’Œä¸»ç‚¹ cxâ€‹,cyâ€‹ï¼‰å°†å…¶åå‘æŠ•å½±åˆ°**å½’ä¸€åŒ–å›¾åƒå¹³é¢**ä¸Šçš„åæ ‡ (xnâ€‹,ynâ€‹)ï¼š
    
    ```
    x_n = (u_{undistorted} - c_x) / f_x
    y_n = (v_{undistorted} - c_y) / f_y
    ```
    
    è¿™é‡Œçš„ (xnâ€‹,ynâ€‹) æ˜¯å‡è®¾æ²¡æœ‰ç•¸å˜çš„æƒ…å†µä¸‹ï¼Œ3Dä¸–ç•Œç‚¹æŠ•å½±åˆ°å›¾åƒå¹³é¢ä¸Šçš„åæ ‡ã€‚
    
4. **åº”ç”¨ç•¸å˜æ¨¡å‹ï¼ˆåå‘ç•¸å˜ï¼‰:** æ¥ä¸‹æ¥ï¼Œä½ éœ€è¦ä½¿ç”¨å·²çŸ¥çš„å¾„å‘ç•¸å˜å’Œåˆ‡å‘ç•¸å˜æ¨¡å‹ä»¥åŠå®ƒä»¬çš„ç³»æ•°ï¼Œè®¡ç®—å‡ºåœ¨åŸå§‹ç•¸å˜å›¾åƒä¸­ï¼Œå“ªä¸ªå½’ä¸€åŒ–åæ ‡ (xdâ€‹,ydâ€‹) å¯¹åº”äºå½“å‰çš„æ— ç•¸å˜å½’ä¸€åŒ–åæ ‡ (xnâ€‹,ynâ€‹)ã€‚è¿™ä¸ªè¿‡ç¨‹æ˜¯**åå‘**åº”ç”¨ç•¸å˜æ¨¡å‹ã€‚
    
    ç•¸å˜æ¨¡å‹é€šå¸¸æè¿°çš„æ˜¯å¦‚ä½•ä»æ— ç•¸å˜çš„ç‚¹ (xnâ€‹,ynâ€‹) æ˜ å°„åˆ°ç•¸å˜çš„ç‚¹ (xdâ€‹,ydâ€‹)ï¼š
    
    ```
    r^2 = x_n^2 + y_n^2
    x_d = x_n (1 + k_1 r^2 + k_2 r^4 + k_3 r^6 + ...) + 2p_1 x_n y_n + p_2 (r^2 + 2x_n^2) + ...
    y_d = y_n (1 + k_1 r^2 + k_2 r^4 + k_3 r^6 + ...) + p_1 (r^2 + 2y_n^2) + 2p_2 x_n y_n + ...
    ```
    
    å…¶ä¸­ k1â€‹,k2â€‹,k3â€‹ æ˜¯å¾„å‘ç•¸å˜ç³»æ•°ï¼Œ p1â€‹,p2â€‹ æ˜¯åˆ‡å‘ç•¸å˜ç³»æ•°ã€‚
    
    **åå‘ç•¸å˜æ˜¯ä¸€ä¸ªæ±‚è§£è¿‡ç¨‹ã€‚** å¯¹äºç»™å®šçš„ (xnâ€‹,ynâ€‹)ï¼Œä½ éœ€è¦æ‰¾åˆ° (xdâ€‹,ydâ€‹) ä½¿å¾—å®ƒåœ¨ç»è¿‡ç•¸å˜åä¼šå˜æˆ (xnâ€‹,ynâ€‹)ã€‚è¿™ä¸ªè¿‡ç¨‹å¯èƒ½æ²¡æœ‰ç›´æ¥çš„è§£æè§£ï¼Œé€šå¸¸éœ€è¦ä½¿ç”¨è¿­ä»£æ–¹æ³•ï¼ˆä¾‹å¦‚ç‰›é¡¿æ³•ï¼‰æ¥è¿‘ä¼¼æ±‚è§£ (xdâ€‹,ydâ€‹)ã€‚
    
5. **æŠ•å½±å›åŸå§‹ç•¸å˜å›¾åƒåƒç´ åæ ‡:** ä¸€æ—¦ä½ æ‰¾åˆ°äº†å¯¹åº”çš„å½’ä¸€åŒ–ç•¸å˜åæ ‡ (xdâ€‹,ydâ€‹)ï¼Œä½ éœ€è¦ä½¿ç”¨ç›¸åŒçš„ç›¸æœºå†…å‚å°†å…¶æŠ•å½±å›åŸå§‹ç•¸å˜å›¾åƒçš„åƒç´ åæ ‡ (udistortedâ€‹,vdistortedâ€‹)ï¼š
    
    ```
    u_{distorted} = f_x * x_d + c_x
    v_{distorted} = f_y * y_d + c_y
    ```
    
    è¿™é‡Œçš„ (udistortedâ€‹,vdistortedâ€‹) æ˜¯åŸå§‹ç•¸å˜å›¾åƒä¸­å¯¹åº”äºæ–°å›¾åƒåƒç´  (uundistortedâ€‹,vundistortedâ€‹) çš„æµ®ç‚¹æ•°åæ ‡ã€‚
    
6. **åƒç´ æ’å€¼:** ç”±äºè®¡ç®—å‡ºçš„ (udistortedâ€‹,vdistortedâ€‹) å¾€å¾€ä¸æ˜¯æ•´æ•°åƒç´ åæ ‡ï¼Œä½ éœ€è¦ä»åŸå§‹ç•¸å˜å›¾åƒä¸­ï¼Œæ ¹æ®è¿™ä¸ªæµ®ç‚¹æ•°åæ ‡å‘¨å›´çš„åƒç´ å€¼è¿›è¡Œæ’å€¼ï¼Œä»¥ç¡®å®šæ–°å›¾åƒåƒç´  (uundistortedâ€‹,vundistortedâ€‹) çš„é¢œè‰²å€¼ã€‚å¸¸ç”¨çš„æ’å€¼æ–¹æ³•åŒ…æ‹¬ï¼š
    
    - **æœ€è¿‘é‚»æ’å€¼ (Nearest Neighbor Interpolation):** é€‰æ‹©è·ç¦»æœ€è¿‘çš„åŸå§‹åƒç´ å€¼ã€‚ç®€å•ä½†å¯èƒ½äº§ç”Ÿé”¯é½¿æ„Ÿã€‚
    - **åŒçº¿æ€§æ’å€¼ (Bilinear Interpolation):** ä½¿ç”¨å‘¨å›´ 2x2 çš„åŸå§‹åƒç´ è¿›è¡ŒåŠ æƒå¹³å‡ã€‚å¹³æ»‘æ•ˆæœè¾ƒå¥½ï¼Œå¸¸ç”¨ã€‚
    - **åŒä¸‰æ¬¡æ’å€¼ (Bicubic Interpolation):** ä½¿ç”¨å‘¨å›´ 4x4 çš„åŸå§‹åƒç´ è¿›è¡Œæ›´å¤æ‚çš„åŠ æƒå¹³å‡ã€‚å¹³æ»‘æ•ˆæœæ›´å¥½ä½†è®¡ç®—é‡æ›´å¤§ã€‚

**æ€»ç»“:**

å»ç•¸å˜çš„è¿‡ç¨‹é€šå¸¸æ˜¯â€œåå‘æ˜ å°„â€å’Œâ€œæ’å€¼â€çš„ç»“åˆï¼š

1. éå†**æœªç•¸å˜å›¾åƒ**çš„æ¯ä¸ªåƒç´ ã€‚
2. è®¡ç®—è¯¥åƒç´ åœ¨**å½’ä¸€åŒ–æ— ç•¸å˜å¹³é¢**ä¸Šçš„åæ ‡ã€‚
3. é€šè¿‡**åå‘ç•¸å˜æ¨¡å‹**æ‰¾åˆ°å¯¹åº”çš„**å½’ä¸€åŒ–ç•¸å˜å¹³é¢**ä¸Šçš„åæ ‡ã€‚
4. å°†è¯¥ç•¸å˜å¹³é¢åæ ‡æŠ•å½±å›**åŸå§‹ç•¸å˜å›¾åƒ**çš„åƒç´ åæ ‡ã€‚
5. ä½¿ç”¨**æ’å€¼**æ–¹æ³•ä»åŸå§‹ç•¸å˜å›¾åƒä¸­è·å–è¯¥æµ®ç‚¹æ•°åæ ‡å¤„çš„åƒç´ å€¼ï¼Œå¹¶å°†å…¶èµ‹ç»™æœªç•¸å˜å›¾åƒçš„å½“å‰åƒç´ ã€‚

è¿™ç§æ–¹æ³•èƒ½å¤Ÿä¿è¯ç”Ÿæˆä¸€ä¸ªå®Œæ•´ä¸”è§„åˆ™çš„æœªç•¸å˜å›¾åƒï¼Œå¹¶ä¸”é€šè¿‡æ’å€¼èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨åŸå§‹å›¾åƒçš„åƒç´ ä¿¡æ¯ã€‚è¿™ä¹Ÿæ˜¯ OpenCV ç­‰åº“ä¸­ `cv::undistort()` å’Œ `cv::remap()` ç­‰å‡½æ•°èƒŒåå®ç°çš„ä¸»è¦é€»è¾‘ã€‚


---
### 3. Minimal PnP

****Problem:**** What is the minimum number of correspondences for pose estimation? Â 

****Answer:**** 3 for P3P, 4+ for RANSAC-PnP.

  

---

  

### 4. SE(3) Pose Update

****Problem:**** How do you update pose using Lie algebra? Â 

****Answer:**** Â 

  

<div class="math">

T \leftarrow \exp(\delta\xi^\wedge) T

</div>

  

---

  

### 5. Rodriguesâ€™s Formula

****Problem:**** What does the function look like? Â 

****Answer:**** Â 
  ![Pasted image 20250404104752.png](3D_Vision_Interview_questions/Pasted%20image%2020250404104752.png)

æç¾¤ä¸Šè¡¨ç¤ºï¼š

![Pasted image 20250404110516.png](3D_Vision_Interview_questions/Pasted%20image%2020250404110516.png)
#### SE(3)
Let's break down why the upper right element of the matrix exponential `exp(Î¾^)` is as shown. The matrix `Î¾^` is likely a 4x4 matrix in the form used in rigid body transformations, where the upper left 3x3 block represents an angular velocity and the upper right 3x1 block represents a linear velocity.

Given:

```
exp(Î¾^) = [ Î£ (1/n!) (Ï†^)^n     Î£ (1/(n+1)!) (Ï†^)^n Ï ]
          [      0^T                 1          ]
```

And we know that `Î¾^` can be decomposed (in a simplified view for this explanation) into:

```
Î¾^ = [ Ï†^   Ï ]
     [ 0    0 ]
```

Where:

- `Ï†^` is a 3x3 skew-symmetric matrix representing the angular velocity vector `Ï‰` (such that `Ï†^v = Ï‰ Ã— v`).
- `Ï` is a 3x1 column vector representing the linear velocity.
- `0^T` is a 1x3 zero row vector.
- `0` in the bottom right is a scalar zero.

Now let's consider the exponential series expansion of `exp(Î¾^)`:

```
exp(Î¾^) = I + Î¾^ + (1/2!) Î¾^2 + (1/3!) Î¾^3 + ... + (1/n!) Î¾^n + ...
```

Let's compute the powers of `Î¾^`:

```
Î¾^2 = [ Ï†^   Ï ] [ Ï†^   Ï ] = [ Ï†^2    Ï†^Ï ]
      [ 0    0 ] [ 0    0 ]   [  0     0  ]

Î¾^3 = Î¾^2 Î¾^ = [ Ï†^2    Ï†^Ï ] [ Ï†^   Ï ] = [ Ï†^3    Ï†^2Ï ]
              [  0     0  ] [ 0    0 ]   [  0     0  ]

...

Î¾^n = [ Ï†^n    Ï†^(n-1)Ï ]
      [  0     0      ]
```

Now, let's look at the upper right 3x1 block of the `exp(Î¾^)` series:

Upper Right = `0` (from I) + `Ï` (from Î¾^) + `(1/2!) Ï†^Ï` (from Î¾^2) + `(1/3!) Ï†^2Ï` (from Î¾^3) + ... + `(1/n!) Ï†^(n-1)Ï` + ...

We can factor out `Ï` from all terms except the first (which is 0):

Upper Right = `Ï + (1/2!) Ï†^Ï + (1/3!) Ï†^2Ï + ... + (1/n!) Ï†^(n-1)Ï + ...`

Now, let's look at the second term in the given `exp(Î¾^)` matrix:

```
Î£ (1/(n+1)!) (Ï†^)^n Ï = (1/1!) Ï†^0 Ï + (1/2!) Ï†^1 Ï + (1/3!) Ï†^2 Ï + ... + (1/(n+1)!) Ï†^n Ï + ...
                     = I Ï + (1/2!) Ï†^Ï + (1/3!) Ï†^2 Ï + ... + (1/(n+1)!) Ï†^n Ï + ...
                     = Ï + (1/2!) Ï†^Ï + (1/3!) Ï†^2 Ï + ... + (1/(n+1)!) Ï†^n Ï + ...
```

Notice that the power of `Ï†^` in each term of our derived "Upper Right" block is one less than the power of `Ï†^` in the corresponding term of the given matrix's upper right block's summation index. This is precisely accounted for by the `(n+1)!` in the denominator instead of `n!` and the `Ï†^n` instead of `Ï†^(n-1)`.

Therefore, the upper right block of the exponential of `Î¾^` is indeed `Î£ (1/(n+1)!) (Ï†^)^n Ï`. This form arises naturally from the matrix exponential series when `Î¾^` has the specific block structure shown (or a related form depending on the exact definition of `Î¾^` used in your context, which seems to be related to twist coordinates in screw theory or Lie group exponentials for rigid body motion).

The structure of `Î¾^` and the properties of the matrix exponential lead to this specific form in the upper right block, which is related to the integrated effect of the angular velocity on the linear velocity over the "time" parameter (which is often represented by `Î¸` or `Ï†` in rotation contexts). This is also connected to the concept of the **Jacobian of the exponential map** in Lie group theory.
![Pasted image 20250404125526.png](3D_Vision_Interview_questions/Pasted%20image%2020250404125526.png)
![Pasted image 20250404132836.png](3D_Vision_Interview_questions/Pasted%20image%2020250404132836.png)
## ğŸ“· Calibration

  

### 6. 3D to 2D Projection Equation

****Problem:**** Derive the basic projection formula. Â 

****Answer:**** Â 

  

<div class="math">

u = K [R|t] X

</div>

  

---

  

### 7. IMU-Camera Calibration

****Problem:**** How to spatially calibrate IMU and camera? Â 

****Answer:**** Â 

  

<div class="math">

T_{W}^{I}(t) = T_{IC} \cdot T_{W}^{C}(t)

</div>

  

---

  

### 8. Hand-Eye Calibration

****Problem:**** Define the hand-eye problem. Â 

****Answer:**** Â 

  ![Pasted image 20250404161646.png](3D_Vision_Interview_questions/Pasted%20image%2020250404161646.png)
  ![Pasted image 20250404163634.png](3D_Vision_Interview_questions/Pasted%20image%2020250404163634.png)
  ![Pasted image 20250404163707.png](3D_Vision_Interview_questions/Pasted%20image%2020250404163707.png)
  ![Pasted image 20250404163839.png](3D_Vision_Interview_questions/Pasted%20image%2020250404163839.png)
  ![Pasted image 20250404171938.png](3D_Vision_Interview_questions/Pasted%20image%2020250404171938.png)
  

<div class="math">

AX = XB

</div>
---

  

### 9. Camera Intrinsics from Chessboard

****Problem:**** How to estimate intrinsics from a checkerboard? Â 

****Answer:**** Zhangâ€™s method: detect corners, estimate homographies, solve for K.

  

---

  

### 10. Multi-Camera Calibration

****Problem:**** How to calibrate multiple cameras? Â 

****Answer:**** Minimize joint reprojection error across all views.

  

---

  

## ğŸ” Multi-Sensor Fusion / VIO

  

### 11. VIO Measurement Model

****Problem:**** What are the models for VIO? Â 

****Answer:**** Â 

Visual: reprojection error Â 

Inertial: preintegration error Â 

  

<div class="math">
r_{imu} = \hat{x}_{i+1} - f(\hat{x}_i, \hat{u}_{i \rightarrow i+1})
</div>

  

---

  

### 12. IMU-Camera Fusion via EKF

****Problem:**** How to fuse IMU and camera in filtering? Â 

****Answer:**** EKF: IMU predicts, camera updates.

  

---

  

### 13. IMU Preintegration

****Problem:**** What is it and why useful? Â 

****Answer:**** Avoids re-integrating during each iteration.

  

---

  

### 14. Monocular VIO Scale Init

****Problem:**** How to estimate scale? Â 

****Answer:**** Align visual motion to IMU preintegration.

  

---

  

### 15. Accelerometer Bias

****Problem:**** How to handle it? Â 

****Answer:**** Model bias in state and optimize/filter.

  

---

  

## ğŸ§® Nonlinear Optimization

  

### 16. Gauss-Newton vs LM

****Problem:**** Whatâ€™s the difference? Â 

****Answer:**** LM adds damping: Â 

  

<div class="math">

(J^T J + \lambda I)\delta = -J^T r

</div>

  

---

  

### 17. Cost Function Linearization

****Problem:**** How to linearize nonlinear cost? Â 

****Answer:**** Â 

  

<div class="math">

r(x + \delta) \approx r(x) + J \delta

</div>

  

---

  

### 18. Schur Complement in BA

****Problem:**** Where is Schur used? Â 

****Answer:**** To marginalize landmarks: Â 

  

<div class="math">

S = A - BC^{-1}B^T

</div>

  

---

  

### 19. Observability in VIO

****Problem:**** How to ensure it? Â 

****Answer:**** Motion excitation, overlapping landmarks, good baseline.

  

---

  

### 20. Null Space in VIO

****Problem:**** Whatâ€™s unobservable? Â 

****Answer:**** Global position, yaw, scale (in monocular)

  

---

### 21.  Bundle Adjustment
  ![Pasted image 20250404095619.png](3D_Vision_Interview_questions/Pasted%20image%2020250404095619.png)

---

  ![Pasted image 20250404095640.png](3D_Vision_Interview_questions/Pasted%20image%2020250404095640.png)
![Pasted image 20250404095654.png](3D_Vision_Interview_questions/Pasted%20image%2020250404095654.png)
![Pasted image 20250404095729.png](3D_Vision_Interview_questions/Pasted%20image%2020250404095729.png)
![Pasted image 20250404095754.png](3D_Vision_Interview_questions/Pasted%20image%2020250404095754.png)
![Pasted image 20250404095812.png](3D_Vision_Interview_questions/Pasted%20image%2020250404095812.png)

![Pasted image 20250404095828.png](3D_Vision_Interview_questions/Pasted%20image%2020250404095828.png)

### 22.  æç¾¤å’Œæä»£æ•°

åå¯¹ç§°é˜µï¼šSkew-symmetric matrix
A skew-symmetric matrix transforms a cross product into a matrix multiplication.


![Pasted image 20250404105553.png](3D_Vision_Interview_questions/Pasted%20image%2020250404105553.png)
![Pasted image 20250404105635.png](3D_Vision_Interview_questions/Pasted%20image%2020250404105635.png)
![Pasted image 20250404105516.png](3D_Vision_Interview_questions/Pasted%20image%2020250404105516.png)

![Pasted image 20250404110321.png](3D_Vision_Interview_questions/Pasted%20image%2020250404110321.png)

### 22.  NLS, Gaussian Newton and LM

![Pasted image 20250404140014.png](3D_Vision_Interview_questions/Pasted%20image%2020250404140014.png)
![Pasted image 20250404140133.png](3D_Vision_Interview_questions/Pasted%20image%2020250404140133.png)
![Pasted image 20250404140152.png](3D_Vision_Interview_questions/Pasted%20image%2020250404140152.png)

![Pasted image 20250404140247.png](3D_Vision_Interview_questions/Pasted%20image%2020250404140247.png)
![Pasted image 20250404140316.png](3D_Vision_Interview_questions/Pasted%20image%2020250404140316.png)
**Jacobian matrix** contains all the **first-order partial derivatives**

![Pasted image 20250404141407.png](3D_Vision_Interview_questions/Pasted%20image%2020250404141407.png)
![Pasted image 20250404141454.png](3D_Vision_Interview_questions/Pasted%20image%2020250404141454.png)

![Pasted image 20250404141526.png](3D_Vision_Interview_questions/Pasted%20image%2020250404141526.png)
![Pasted image 20250404141546.png](3D_Vision_Interview_questions/Pasted%20image%2020250404141546.png)

### 23.  Camera Calibration

The principle behind camera calibration is to **mathematically model the mapping between a 3D point in the real world and its 2D projection onto the image sensor**, and then to **estimate the parameters of this model** using known correspondences between 3D points and their 2D image locations.

Here's a breakdown of the underlying principles:

**1. Camera Model:**

The foundation of camera calibration is a mathematical model that describes how a 3D world point (X,Y,Z)wâ€‹ is projected to a 2D pixel coordinate (u,v) in the image. The most common model is the **pinhole camera model**, which is often augmented to account for lens distortions.

- **Pinhole Model:**
    
    - Assumes that light rays from the 3D world pass through a single point (the pinhole or optical center) and project onto the image plane.
    - The relationship between a 3D point in the camera coordinate system (X,Y,Z)câ€‹ and its ideal projection (x,y) on the image plane (in metric units) is given by perspective projection:
        
        ```
        x = f * (X / Z)
        y = f * (Y / Z)
        ```
        
        where f is the focal length (the distance between the optical center and the image plane).
    - These ideal image plane coordinates (x,y) are then converted to pixel coordinates (u,v) using the camera's intrinsic parameters:
        
        ```
        u = f_x * x + c_x
        v = f_y * y + c_y
        ```
        
        where fxâ€‹ and fyâ€‹ are the focal lengths in pixel units along the u and v axes, and (cxâ€‹,cyâ€‹) is the principal point (the center of the image in pixel coordinates).
- **Lens Distortion Model:**
    
    - Real lenses introduce distortions that cause deviations from the ideal pinhole projection. The most common distortions are radial and tangential.
    - **Radial Distortion:** Causes straight lines to appear curved. It's typically modeled using polynomial terms of the radial distance from the image center:
        
        ```
        x_d = x_n (1 + k_1 r^2 + k_2 r^4 + k_3 r^6 + ...)
        y_d = y_n (1 + k_1 r^2 + k_2 r^4 + k_3 r^6 + ...)
        ```
        
        where (xnâ€‹,ynâ€‹) are the normalized image coordinates, (xdâ€‹,ydâ€‹) are the distorted normalized coordinates, r2=xn2â€‹+yn2â€‹, and k1â€‹,k2â€‹,k3â€‹,... are the radial distortion coefficients.
    - **Tangential Distortion:** Occurs due to imperfect alignment of lens elements. It's typically modeled as:
        
        ```
        x_d = x_d + (2p_1 x_n y_n + p_2 (r^2 + 2x_n^2) + ...)
        y_d = y_d + (p_1 (r^2 + 2y_n^2) + 2p_2 x_n y_n + ...)
        ```
        
        where p1â€‹,p2â€‹,... are the tangential distortion coefficients.

**2. Establishing Correspondences:**

Camera calibration requires knowing the 3D coordinates of a set of points in the real world and their corresponding 2D pixel coordinates in one or more images. A common way to achieve this is by using a calibration pattern with known geometry, such as a checkerboard.

- **Checkerboard:** The corners of the squares on a checkerboard have well-defined 3D relative positions. By placing the checkerboard in the camera's field of view and capturing images from different angles, we can extract the 2D pixel coordinates of these corners in each image.
- **Object Points:** The 3D coordinates of the checkerboard corners are known relative to the checkerboard itself. We can define a world coordinate system where the checkerboard lies on a plane (e.g., Z=0).
- **Image Points:** The 2D pixel coordinates of the detected checkerboard corners in each image are the corresponding image points.

**3. Parameter Estimation (Optimization):**

The goal of calibration is to find the intrinsic parameters (fxâ€‹,fyâ€‹,cxâ€‹,cyâ€‹,k1â€‹,k2â€‹,p1â€‹,p2â€‹,...) and the extrinsic parameters (rotation R and translation t for each camera pose relative to the world coordinate system) that best explain the observed correspondences between the 3D object points and their 2D image points.

This is typically formulated as a **non-linear least squares optimization problem**. The error function to be minimized is the **reprojection error**, which is the squared difference between the observed 2D image points and the 2D image points predicted by the camera model using the current estimates of the parameters.

- **Reprojection:** For each known 3D object point, we project it into the 2D image plane using the current camera model parameters (including intrinsics, extrinsics, and distortion).
- **Error Calculation:** We calculate the distance between the predicted 2D point and the actually observed 2D point in the image.
- **Minimization:** An optimization algorithm (like the Levenberg-Marquardt algorithm) iteratively adjusts the camera parameters to minimize the sum of the squared reprojection errors over all the calibration images and all the detected points.

**4. Mathematical Formulation:**
![Pasted image 20250404160027.png](3D_Vision_Interview_questions/Pasted%20image%2020250404160027.png)
**In essence, camera calibration is about finding the set of camera parameters that best explains how 3D points in the world are mapped to 2D points in the image by minimizing the discrepancy between the predicted and observed image locations of known 3D points.** This process allows us to correct for lens distortions and to establish the relationship between the camera's coordinate system and the real world.

In camera calibration, the **camera pose (extrinsic parameters)** and the **camera parameters (intrinsic parameters and distortion coefficients)** are typically optimized **together** in a process that often involves **iterative optimization**.

Here's a breakdown of how this works:

**1. The Optimization Problem:**

As explained previously, the goal of camera calibration is to minimize the **reprojection error**, which is the difference between the observed 2D image points and the 2D projections of the corresponding 3D world points using the current estimates of both camera pose and camera parameters. The total error to minimize is the sum of squared reprojection errors over all calibration images and all detected feature points.

**2. The Variables to Optimize:**

The optimization process aims to find the values for the following variables that minimize the reprojection error:

- **Intrinsic Parameters:**
    - Focal lengths (fxâ€‹,fyâ€‹)
    - Principal point (cxâ€‹,cyâ€‹)
    - Distortion coefficients (k1â€‹,k2â€‹,k3â€‹,p1â€‹,p2â€‹, and potentially higher-order terms)
- **Extrinsic Parameters (for each calibration image):**
    - Rotation matrix (R) or rotation vector (e.g., Rodrigues vector) representing the camera's orientation relative to the world coordinate system (often defined by the calibration pattern).
    - Translation vector (t) representing the camera's position relative to the world coordinate system.

**3. Iterative Optimization:**

Due to the non-linear nature of the camera model (especially with the inclusion of distortion) and the relationship between the parameters and the reprojection error, the optimization problem is typically solved using **iterative non-linear least squares algorithms**. The most common algorithm used for this purpose is the **Levenberg-Marquardt (LM) algorithm**.

**How the Levenberg-Marquardt (LM) Algorithm Works (Simplified):**

The LM algorithm is an iterative technique that combines aspects of two other optimization methods:

- **Gradient Descent:** When far from the minimum, the algorithm behaves more like gradient descent, taking small steps in the direction of the negative gradient of the error function. This helps to move towards the general vicinity of the optimal solution.
- **Gauss-Newton:** When closer to the minimum, the algorithm behaves more like the Gauss-Newton method, which uses a second-order approximation of the error function (based on the Jacobian) to take larger, more direct steps towards the minimum. This often leads to faster convergence near the optimal solution.

The LM algorithm adaptively adjusts a damping parameter (Î») to control the balance between gradient descent and Gauss-Newton behavior.

- **Large Î»:** Favors gradient descent (smaller steps, more stable).
- **Small Î»:** Favors Gauss-Newton (larger steps, faster convergence near the minimum).

At each iteration of the LM algorithm:
![Pasted image 20250404160253.png](3D_Vision_Interview_questions/Pasted%20image%2020250404160253.png)

**In summary, camera calibration optimizes camera pose and camera parameters simultaneously using iterative non-linear least squares methods like the Levenberg-Marquardt algorithm. This algorithm iteratively refines the parameter estimates by minimizing the reprojection error, considering the influence of both intrinsic and extrinsic parameters on the final image projection.**

What's the dimension of J? (2mn)\*(4+d+6m) (m is the image numbers, n is the checkboard corners)
N\*M checker board only contains (N-1)\*(M-1) corners.

### 24.  Hand Eye Calibration
